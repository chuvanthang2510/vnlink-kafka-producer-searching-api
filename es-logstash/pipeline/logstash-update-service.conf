input {
  file {
    path => ["D:/APISearch-Java-ES-Logstash-Kafka-Docker/es-logstash/dataV2/service_test.txt"]
    start_position => "beginning"
    sincedb_path => "NUL"  # Windows: NUL, Linux thì /dev/null
    codec => plain { charset => "UTF-8" }
    mode => "read"
    file_completed_action => "log"
    file_completed_log_path => "D:/APISearch-Java-ES-Logstash-Kafka-Docker/es-logstash/data/completed_files.log"
  }
}

filter {
  # Parse CSV với dấu phân cách ;
  csv {
    separator => ";"
    columns => ["orderCode", "ID", "serviceCode", "subService", "serviceId", "code"]
    skip_header => true
  }

  # Làm sạch orderCode để dùng làm document_id (nếu có ký tự đặc biệt)
  mutate {
    gsub => ["orderCode", "[^a-zA-Z0-9_-]", "_"]
  }

  # Rename ID to id
  mutate {
    rename => { "ID" => "id" }
  }

  # Biến thành sự kiện grouped theo orderCode
  aggregate {
    task_id => "%{orderCode}"
    code => "
      map['orderCode'] = event.get('orderCode')
      map['services'] ||= []
      map['services'] << {
        'id' => event.get('id'),
        'serviceCode' => event.get('serviceCode'),
        'subService' => event.get('subService'),
        'serviceId' => event.get('serviceId'),
        'code' => event.get('code')
      }
    "
    push_map_as_event_on_timeout => true
    timeout => 5
    timeout_tags => ["_aggregatetimeout"]
    timeout_task_id_field => "orderCode"
  }

  # Xoá event trung gian
  if "_aggregatetimeout" not in [tags] {
    drop { }
  }

  # Xóa các trường không cần thiết của Logstash
  mutate {
    remove_field => ["@version", "host", "path"]
  }
}

output {
  if [orderCode] {
    elasticsearch {
      hosts => ["http://103.21.149.190:9200"]
      index => "orders_import"
      document_id => "%{orderCode}"  # đảm bảo không trùng ID
      action => "update"             # cập nhật nếu có, tạo mới nếu không
      doc_as_upsert => true
      user => "elastic"
      password => "M6a5K2XgHhWJYAZUsGF4mRc"
    }

    # Ghi log lỗi parse CSV vào file riêng
    if "_csvparsefailure" in [tags] {
      file {
        path => "D:/APISearch-Java-ES-Logstash-Kafka-Docker/es-logstash/data/error.log"
        codec => json_lines
      }
    }

    stdout { codec => rubydebug }
  }
}
